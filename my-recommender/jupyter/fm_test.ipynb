{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n2.0\n[3. 3.]\n[2.0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "var1 = tf.get_variable('var1',shape=[2,],initializer=tf.ones_initializer)\n",
    "var2 = tf.get_variable('var2',shape=[],initializer=tf.ones_initializer)\n",
    "var2= tf.multiply(var2,2)\n",
    "res = tf.add(tf.multiply([1.,1.],var1),var2)\n",
    "grad = tf.gradients(res,var2)\n",
    "weight_0 = tf.get_variable('weigth_0',shape=[],initializer=tf.ones_initializer)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(var1))\n",
    "    print(sess.run(var2))\n",
    "    print(sess.run(res))\n",
    "    print(sess.run(grad))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19.  0.  0.  0.  1.  1.  0.  0.  0.]\n [33.  0.  0.  1.  0.  0.  1.  0.  0.]\n [55.  0.  1.  0.  0.  0.  0.  1.  0.]\n [20.  1.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[137.]\n [235.]\n [389.]\n [144.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[18.75,  5.  , 13.75,  0.  ,  0.  ,  0.  ,  0.  , 13.75,  5.  ],\n       [18.75,  5.  , 13.75,  0.  ,  0.  ,  0.  ,  0.  , 13.75,  5.  ]],\n      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "train = [\n",
    "    {\"user\": \"1\", \"item\": \"5\", \"age\": 19},\n",
    "    {\"user\": \"2\", \"item\": \"43\", \"age\": 33},\n",
    "    {\"user\": \"3\", \"item\": \"20\", \"age\": 55},\n",
    "    {\"user\": \"4\", \"item\": \"10\", \"age\": 20},\n",
    "]\n",
    "# train = [\n",
    "#         {\"user\": \"1\", \"age\": 19},\n",
    "#         {\"user\": \"2\", \"age\": 33},\n",
    "#         {\"user\": \"3\", \"age\": 55},\n",
    "#         {\"user\": \"4\", \"age\": 20},\n",
    "#     ]\n",
    "v = DictVectorizer()\n",
    "print(v.fit_transform(train).toarray())\n",
    "X = tf.constant(v.fit_transform(train).toarray(), tf.float32)\n",
    "\n",
    "y = tf.constant(np.array([[1], [1], [-1], [-1]]), dtype=tf.float32)\n",
    "weight_0 = tf.get_variable('weight_0', shape=[1], initializer=tf.zeros_initializer)\n",
    "weights = tf.get_variable('weights', shape=[X.shape[1], 1], initializer=tf.ones_initializer)\n",
    "v_matrix1 = tf.get_variable('vectors1', shape=[2, X.shape[1]], initializer=tf.ones_initializer)\n",
    "v_matrix2 = tf.get_variable('vectors2', shape=[2, X.shape[1]], initializer=tf.ones_initializer)\n",
    "y_ = (weight_0 + tf.matmul(X, weights))\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "for f_indices in combinations(range(X.shape[1]), 2):\n",
    "    f_prod, v_prod = tf.ones((4, 1)), tf.ones((2, 1))\n",
    "    for f_index in f_indices:\n",
    "        f_prod = tf.multiply(f_prod, X[:, f_index:f_index + 1])\n",
    "        v_prod = tf.multiply(v_prod, v_matrix1[:, f_index:f_index + 1])\n",
    "    y_ = tf.add(y_, tf.multiply(f_prod, tf.reduce_sum(v_prod)))\n",
    "\n",
    "for f_indices in combinations(range(X.shape[1]), 3):\n",
    "    f_prod, v_prod = tf.ones((4, 1)), tf.ones((2, 1))\n",
    "    for f_index in f_indices:\n",
    "        f_prod = tf.multiply(f_prod, X[:, f_index:f_index + 1])\n",
    "        v_prod = tf.multiply(v_prod, v_matrix2[:, f_index:f_index + 1])\n",
    "    y_ = tf.add(y_, tf.multiply(f_prod, tf.reduce_sum(v_prod)))\n",
    "\n",
    "loss = tf.maximum(0., 1 - tf.multiply(y, y_))\n",
    "loss = tf.reduce_mean(loss)\n",
    "grad = tf.gradients(loss, v_matrix2)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(y_))\n",
    "    print(sess.run(loss))\n",
    "    print(sess.run(grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19.  0.  0.  0.  1.  1.  0.  0.  0.]\n [33.  0.  0.  1.  0.  0.  1.  0.  0.]\n [55.  0.  1.  0.  0.  0.  0.  1.  0.]\n [20.  1.  0.  0.  0.  0.  0.  0.  1.]]\n[[0. 0. 1. 0.]\n [0. 0. 1. 0.]\n [0. 0. 1. 0.]\n [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "train = [\n",
    "    {\"user\": \"1\", \"item\": \"5\", \"age\": 19},\n",
    "    {\"user\": \"2\", \"item\": \"43\", \"age\": 33},\n",
    "    {\"user\": \"3\", \"item\": \"20\", \"age\": 55},\n",
    "    {\"user\": \"4\", \"item\": \"10\", \"age\": 20},\n",
    "]\n",
    "v = DictVectorizer()\n",
    "print(v.fit_transform(train).toarray())\n",
    "X = tf.constant(v.fit_transform(train).toarray(), tf.float32)\n",
    "f_prod,v_prod = tf.ones((2,1)),tf.ones((4,1))\n",
    "res = tf.multiply(v_prod,X[:,2])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print(sess.run(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
